{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_df = pd.read_csv(\"ipatest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(import_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hice', \"'i-se\"],\n",
       "       ['combinación', \"kom-bi-na-'si̯on\"],\n",
       "       ['inicio', \"i-'ni-si̯o\"],\n",
       "       ['educación', \"e-ðu-ka-'si̯on\"],\n",
       "       ['hasta', \"'as-ta\"],\n",
       "       ['ojo', \"'o-ho\"],\n",
       "       ['casi', \"'ka-si\"],\n",
       "       ['usar', \"u-'saɾ\"],\n",
       "       ['funcionar', \"fun-si̯o-'naɾ\"],\n",
       "       ['cantar', \"kan-'taɾ\"],\n",
       "       ['ayuda', \"a-'ju-ða\"],\n",
       "       ['hombre', \"'om-bɾe\"],\n",
       "       ['está', \"es-'ta\"],\n",
       "       ['sabe', \"'sa-βe\"],\n",
       "       ['oportunidad', \"o-poɾ-tu-ni-'ðað\"],\n",
       "       ['toque', \"'to-ke\"],\n",
       "       ['él', \"'el\"],\n",
       "       ['su', \"'su\"],\n",
       "       ['hermana', \"eɾ-'ma-na\"],\n",
       "       ['esta', \"'es-ta\"],\n",
       "       ['taza', \"'ta-sa\"],\n",
       "       ['importante', \"im-poɾ-'tan-te\"],\n",
       "       ['qué', \"'ke\"],\n",
       "       ['el', \"'el\"],\n",
       "       ['tanto', \"'tan-to\"],\n",
       "       ['son', \"'son\"],\n",
       "       ['masa', \"'ma-sa\"],\n",
       "       ['diez', \"'di̯es\"],\n",
       "       ['eso', \"'e-so\"],\n",
       "       ['éxito', \"'ek-si-to\"],\n",
       "       ['extra', \"'eks-tɾa\"],\n",
       "       ['miedo', \"'mi̯e-ðo\"],\n",
       "       ['voy', \"'βoi̯\"],\n",
       "       ['leí', \"le-'i\"],\n",
       "       ['poema', \"po-'e-ma\"],\n",
       "       ['sea', \"'se-a\"],\n",
       "       ['aéreo', \"a-'e-ɾe-o\"],\n",
       "       ['día', \"'di-a\"],\n",
       "       ['leer', \"le-'eɾ\"],\n",
       "       ['trae', \"'tɾa-e\"],\n",
       "       ['ley', \"'lei̯\"],\n",
       "       ['oí', \"o-'i\"],\n",
       "       ['hoy', \"'oi̯\"],\n",
       "       ['reí', \"re-'i\"],\n",
       "       ['rey', \"'rei̯\"],\n",
       "       ['diario', \"'di̯a-ɾi̯o\"],\n",
       "       ['Saúl', \"sa-'ul\"],\n",
       "       ['Paula', \"'pau̯-la\"],\n",
       "       ['oído', \"o-'i-ðo\"],\n",
       "       ['oigo', \"'oi̯-ɣo\"],\n",
       "       ['mi', \"'mi\"],\n",
       "       ['tu', \"'tu\"],\n",
       "       ['Lola', \"'lo-la\"],\n",
       "       ['le', \"'le\"],\n",
       "       ['sonríe', \"son-'ɾi-e\"],\n",
       "       ['patrón', \"pa-'tɾon\"],\n",
       "       ['alto', 'al-to'],\n",
       "       ['yo', \"'ʝo\"],\n",
       "       ['huerta', \"'weɾ-ta\"],\n",
       "       ['huésped', \"'wes-peð\"],\n",
       "       ['cara', \"'ca-ɾa\"],\n",
       "       ['cada', \"'ca-ða\"],\n",
       "       ['siesta', \"'si̯es-ta\"]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this dataset, the x axis is the Spanish word, the y axis is the ipa transcription with the accents and syllable breaks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get a better idea of what the string data actually looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Word:  diario\n",
      "0 d\n",
      "1 i\n",
      "2 a\n",
      "3 r\n",
      "4 i\n",
      "5 o\n"
     ]
    }
   ],
   "source": [
    "# first, let's grab one of the Spanish words\n",
    "spanish_word = array[45][0]\n",
    "print(\"Spanish Word: \", spanish_word)\n",
    "for i,e in enumerate(spanish_word):\n",
    "    print(i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPA Word:  'di̯a-ɾi̯o\n",
      "0 '\n",
      "1 d\n",
      "2 i\n",
      "3 ̯\n",
      "4 a\n",
      "5 -\n",
      "6 ɾ\n",
      "7 i\n",
      "8 ̯\n",
      "9 o\n"
     ]
    }
   ],
   "source": [
    "# let's grab one of the IPA words\n",
    "ipa_word = array[45][1]\n",
    "print(\"IPA Word: \", ipa_word)\n",
    "for i,e in enumerate(ipa_word):\n",
    "    print(i,e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see, the lengths are going to be different. Obviously, there is the addition of the syllable breaks (`-`) and the accent marks (`'`), but there is also the factor of the semi-vowel markings, which are being interpreted as new characters (` ̯`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish Word:  patrón\n",
      "0 p\n",
      "1 a\n",
      "2 t\n",
      "3 r\n",
      "4 ó\n",
      "5 n\n"
     ]
    }
   ],
   "source": [
    "# lets test one more, just to see what it might look like\n",
    "spanish_word2 = array[55][0]\n",
    "print(\"Spanish Word: \", spanish_word2)\n",
    "for i,e in enumerate(spanish_word2):\n",
    "    print(i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPA Word:  pa-'tɾon\n",
      "0 p\n",
      "1 a\n",
      "2 -\n",
      "3 '\n",
      "4 t\n",
      "5 ɾ\n",
      "6 o\n",
      "7 n\n"
     ]
    }
   ],
   "source": [
    "ipa_word2 = array[55][1]\n",
    "print(\"IPA Word: \", ipa_word2)\n",
    "for i,e in enumerate(ipa_word2):\n",
    "    print(i,e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So it looks like the accented \"o\" (`ó`) is still read as a single character. This all is good information to know before moving forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "094fe2711c494eb8fc3c7b741182af166b9f45fe91194cd803edd6afa02ef748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
